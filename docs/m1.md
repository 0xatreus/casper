# M1 Trustworthy Results

## Goal

Make findings reliable enough that teams trust and act on them.
Default experience should emphasize change detection and evidence.

## M1 Deliverables

### Evidence-driven confidence
- Standardize rules for low/medium/high confidence.
- Confidence derives from evidence strength, not just module heuristics.

### Dedupe and correlation
- One root cause per issue.
- Avoid duplicate findings across endpoints or scans.
- Use stable dedupe keys and optional group IDs.

### Baseline diff
- Default view: new vs fixed vs still-present findings.
- Baseline scan is the reference; new findings are the priority.

### Exceptions
- Per-asset or scoped exceptions with expiry and ownership.
- Exceptions suppress noise but stay auditable.

### Recheck
- Scheduled or triggered recheck scans.
- Recheck results update finding status and history.

## Data Model Additions (Suggested)

- Baseline table or BaselineScan metadata.
- FindingGroup table or root_cause_id field.
- Recheck table with status and result_scan_id.
- Exception scope fields (target_id, module, finding_type) to avoid overbroad suppressions.

## API Additions (Suggested)

- `GET /findings` filters: target_id, scan_id, severity, status, since, baseline_id.
- Baseline endpoints: create/get baseline, baseline diff view.
- Recheck endpoints: schedule, list, status.
- Exception management: update/expire, list expired.

## Definition of Done

- Default UI/API shows only new findings since baseline.
- Exceptions are scoped, expiring, and audited.
- Recheck runs are tracked and update finding status.
